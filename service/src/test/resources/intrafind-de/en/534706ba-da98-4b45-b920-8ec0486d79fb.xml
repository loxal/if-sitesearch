<?xml version='1.0' encoding='UTF-8' ?><documents count="50"><Document><url>https://www.intrafind.de/company/glossary/ipma</url><id>07830ACB3F5FF810CC2B79E232FF9645</id><title>IPMA</title><language>en</language><body>IPMA   International Project Management Association, international umbrella organization of Project Management Associations  </body></Document><Document><url>https://www.intrafind.de/products/ifinder5-elastic/benefits-for-your-company-departments/research-development</url><id>8BC266B9CCCA00DFC17C30B580E3BB69</id><title>Benefits for Research &amp; Development</title><language>en</language><body>Research &amp; Development Valuable information can be found enterprise-wide and distributed in a variety of systems. By linking multiple data sources to the iFinder5 elastic, engineers from research and development have access to large data sets. The discovery of historical information is now an accompanying research process - simple, comprehensive and complete. &quot;Don’t reinvent the wheel again and again.&quot;  As an integral part of iFinder5 elastic knowledge workers will find a so called Knowledge Map on the interface that supports complex search queries. Metadata - elaborated from the information resources - provide dynamic filters in the knowledge map. Intuitively, the knowledge workers can link various filters, for example, products with responsible persons, and gradually narrow down the results.   &gt;&gt; back to the company areas</body></Document><Document><url>https://www.intrafind.de/solutions/solutions-for-productivity-increase</url><id>8D05450D0C4BE43535786C2B52916052</id><title>Solutions for Productivity Increase</title><language>en</language><body>Solutions for Productivity Increase IntraFind People Search Who does what in your company? Quickly find the expert in your organization who can answer your question. Big Data Analytics &amp; Big Content Analytics Benefit from the possibility of the iFinder5 elastic to readout largest data volume and enhance it intelligently. Get strongly correlating information packages, which allow real conclusions, at the push of a button. More information&gt;&gt; Classification of Documents You want to know what a document contains without reading it? This is possible. With IntraFind. Search in PowerPoint Libraries You are tired of compiling new slides over and over? Benefit from working with already prepared ones. Or do you want to know how your colleagues present a topic that is of interest for you? Our solution supports you when searching for slides.</body></Document><Document><url>https://www.intrafind.de/company/glossary/semantic-search</url><id>8396C6F8FA84F04F5AE4BE76D1585799</id><title>Semantic search</title><language>en</language><body>Semantic search   A semantic search occurs if the contextual meaning of texts and search queries is considered during the search. In this connection, thesauri, semantic networks or ontologies are used, which contain the background knowledge for the interpretation of search queries.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/relevance</url><id>3219E595558A97682CAB471887A3C654</id><title>Relevance</title><language>en</language><body>Relevance   Enterprise Search and intelligent mechanisms ensure a contextually high-quality hit list with important information corresponding to the search term.  </body></Document><Document><url>https://www.intrafind.de/products/ifinder5-elastic/benefits-for-your-company-departments/it-department</url><id>AD6F54424F91DF17CE7320E4BA8E9908</id><title>Benefits for IT Department</title><language>en</language><body>Benefits for IT Departments IntraFind experts accompany your project from the beginning. There will be a demand analysis and operations planning, implementation and go-live phase and of course we support you during continuous operation. Now for some interesting facts:   The search solution iFinder5 elastic respects access rights (Secure Search). The access rights check is carried out for all documents in the hit list, the auto-completion and for all information on the search interface.  High scalability and load balancing allow real time indexing and reliability, rapid load distribution and thus a quick search in large databases - Big Data Analytics.  The iFinder is operating system independent and can be operated on a dedicated server as well as in a virtual environment. Our solution is highly scalable, it grows with the needs of your business and can be expanded by the number of documents or data sources. The iFinder doesn’t &quot;phone&quot; home - we respect data and IT security. You virtually have no administrative effort    &gt;&gt; back to the company areas</body></Document><Document><url>https://www.intrafind.de/solutions/e-commerce</url><id>8B3A0A858931E53354EFB1743C32DD9E</id><title>Improvement of the search in e-commerce platforms on the internet, media portals and online shops</title><language>en</language><body>E-commerce: how to increase customer satisfaction and buying power with a powerful online shop search   For operators of e-commerce portals (such as online shops or content portals of media companies and publishers), it is essential that visitors spend a long time on the portal, make purchases, evaluate the purchased products positively, recommend the portal and visit it again in the future. Without a doubt, a well-functioning portal search has a large impact on customer satisfaction and loyalty.   Therefore, it is important to develop a better understanding for the needs of the users and assist them with appropriate search functionalities throughout their visit on the website.   In this context, linguistic features are becoming increasingly important, which complement the existing workflows and product suggestions (recommendations) in major e-commerce search engines and significantly improve the quality of search results.   Understanding the client: Search with enhanced language features   With using high-quality text analysis components by IntraFind the portal visitors find both, more and better results. So when searching, it makes no difference whether they are looking for &quot;book&quot; or &quot;books&quot;. The linguistic text analysis by IntraFind ensures that they also find hits containing &quot;book&quot;, &quot;books&quot;, &quot;children&apos;s books&quot; etc. No manual maintenance of rules is needed because the linguistics performs this in the background in high quality.   With the use of the Crosslingual Search, online shops that are available in several languages, can offer and suggest products to their customers for which there is no article description available in the mother tongue of the customers. In the background - unnoticed by the customer - the entered search term is reduced to its base form (e.g. &quot;books&quot; → &quot;book&quot;), translated, and is used for searching in other product descriptions, e.g. in English or French. The number of hits then also contains articles that contain &quot;book&quot; or &quot;livre&quot; in the description text. This way, also when searching in a foreign language, a consistent high hit quality and quantity is available for the customer.   In addition, the customers are supported in their purchase decision by synonym proposals, as the search is extended by relevant terms in a hierarchical thesaurus (refinement, generalization, synonyms), e.g. when searching for &quot;notebook&quot; also &quot;laptop&quot; appears.   Marketing campaigns of the portal operator can be created with any (nested) queries, so that the search for &quot;contact&quot; or any item, exactly returns the desired best hits defined by the portal operator, for example the customer service hotline or the special offers from the current TV advertising campaign.   Besides thesauri also taxonomies or semantic networks and knowledge models can be connected via standard gateways. When the customer has chosen a camera he is not interested in &quot;similar&quot; cameras, but in matching equipment such as lenses, transport bags or memory cards - this is made possible and maintained with a semantic network.   Guided Search   In addition to the linguistic methods shown and the faceted search (restricting the number of hits by selecting product characteristics such as price, manufacturer or color), an intelligent auto-completion helps (e.g. to group proposals from the different product groups and display them clearly) to lead the shop visitors quickly to their desired product.   Assistance with data collection and refinement   The quality of the data (e.g. a detailed and accurate product description including customer ratings) often makes the decisive difference whether a product is purchased or not. IntraFind’s software products help to optimize the quality of the data (and metadata). Metadata such as manufacturer/brand, color, size or price of an item enable the customers to better get along in a system and get to the desired product.   The IntraFind Tagging Service comprehensively supports all processes in which content is created (e.g. product descriptions or editorial posts and articles) and enriches the existing data with newly generated metadata (e.g. product and brand names, people or places).   Fast evaluation possibility for large data sets   The IntraFind Knowledge Map provides a clear 360°-view of the existing data. Besides the navigational support for the customer, for operators of online shops this means the ability to create specific reports; so they can keep track of what products are available or sold out in a particular category. Due to the dynamic display and updating of each category at every click, they get fast answers to their questions without having to use other analysis tools.   Easy integration   The components shown are invariably based on easy accessible services, or can be used as plug-ins without great effort to integrate into existing search solutions based on Lucene, Solr or Elasticsearch.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/lucene</url><id>97143EE4F4D79D96EFA8814159850872</id><title>Lucene</title><language>en</language><body>Lucene   An open source technology, which IntraFind uses as a basis for the Enterprise Search solution iFinder. Many companies use Lucene; IntraFind has expanded this engine into a fast, comprehensive and reliable search engine for companies.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/unstructured-data</url><id>A1DB3F5EE237CEF974EC3C204B10236E</id><title>Unstructured data</title><language>en</language><body>Unstructured data   Unstructured data is digitalized information, which in contrast to structured data does not have an underlying formalized structure, e.g. digital texts in a natural language.  </body></Document><Document><url>https://www.intrafind.de/events_en</url><id>F8B8BC1895084997C01384AAF997BD8D</id><title>Events with IntraFind</title><language>en</language><body>IntraFind Events</body></Document><Document><url>https://www.intrafind.de/solutions/use-cases</url><id>C0774613F89778FE0B81028A22BB6AD0</id><title>Use Cases</title><language>en</language><body>Use Cases Be inspired. Many of our customers use our search solution for various enterprise scenarios. Contact us, if you discover an interesting solution and need an adaptation for your company. Developer Search Benefit from a customized portal with excellent search functionalities that meets the demands of product developers. Media Portals on Company Websites Journalists need specific and newest product information or information from the top management. A media portal enriched with intelligent search mechanisms helps them to get along easily.   Universal Search With only one search box you will get access to all company information consisting of various document types stored in different data sources. Automatic Generation of Newsletters We automatically analyze and classify your most important information sources according to relevant content and provide your employees with a newsletter that contains everything worth knowing. Everything entirely automated, of course. Search in Company Websites Your homepage visitors will thank you. All your customers will quickly and easily find the product they are searching for. Without any detours and without knowing the correct spelling. Shopping Portals &amp; Shop Systems You have many products and product categories in your shopping portal and no automatic categorization? Increase the time your customers spend in your shop and maximize your sale. More information &gt;&gt; Knowledge &amp; Ideas Management Your employees do not only need an overview but also an insight, exact evaluations and facts for specific topics. IntraFind intelligently supports whole research processes.</body></Document><Document><url>https://www.intrafind.de/company/glossary</url><id>16EF8355B8A24C3AC0982D20D738FAB2</id><title>Glossary</title><language>en</language><body>Glossary A Algorithm Annotation API Auto-classification Auto complete B Best practice Big data Boolean search Boolean operators C CMS Committer Connector Content analytics Corpus Crawler CRM Cross-lingual Search Cross-validation D Descriptor DMS Duplicate E E-Commerce elasticsearch Enterprise Search Enterprise Segment Entity Entity Recognition F Facet Full text search G Grid Search Guided Search GUI H Homograph I Index Information Access Information Retrieval Intranet IPMA Indexing J - K KMU Knowledge Map Knowledge Network L Linguistics Log file Lucene M Metadata Metadata generation Morphology N - O Open Source P Proof of Concept (PoC) Q - R Real-time analysis Redundancy Relevance Return on Investment (ROI) S SDK Search-based application / Search-driven application Semantics Semantic descriptors Semantic Search Semi-structured data Scalability Similarity search Solr Stakeholder Structured data Search ergonomy T Tag Tag cloud Tagging Service Taxonomy Test corpus Text analysis Text analytics Text classification Text mining Topic based search Thesaurus Total Cost of Ownership (TCO) Training corpus U Unified Information Access Unstructured data V - W - X - Y - Z -</body></Document><Document><url>https://www.intrafind.de/products/ifinder5-elastic</url><id>1F6016A1733738C2A86523951FC4A4F0</id><title>iFinder5 elastic for a company wide search</title><language>en</language><body>iFinder5 elastic Search. Find. IntraFind. With the launch of the iFinder5 elastic IntraFind offers an optimal solution for finding important information. Read below the possible uses there and your benefits. Intelligent search engine The iFinder5 elastic is a complete solution and can be used immediately. Universal search Connectors link all relevant internal and external data sources to the iFinder5 elastic and thus ensure that nothing important is overlooked. Search of integrated applications Do you have problems to find the right information right away in one of your applications? Replace an existing search in an application, for example, searching in a CMS-system, by searching with the iFinder5 elastic and benefit immediately from all the intelligent functionalities. The extension to universal search in the application by adding additional data sources (e.g. PLM-, CRM-system, Microsoft Exchange) is possible.  Information center With the iFinder5 elastic you get many collaboration tools and small everyday helpers. You can, for example, share information with your colleagues ad hoc, learn new things about the company, find the right contact person and much more.  Solution for knowledge management Consuming research work will be greatly simplified for knowledge workers. You can actively seek or be informed automatically about a particular subject. The universal search across all data sources, ensures a complete hit list and also provides thematically relevant and coherent information. You no longer need to constantly re-invent the wheel.  Content Analytics platform Gain a deep insight into the content of your inventory information, get all linked documents from all data sources at the push of a button and derive therefrom important decisions.  Natural Language Searches with NLP and Deep Learning By intelligent processing of searches and the analysis of predicate argument structures the iFinder5 elastic can interpret and understand natural language search queries. &quot;Presentations on content analytics of the last 4 weeks“ for example, delivers matching new PPT or PDF documents with the topic content analytics in the defined period of time. Usage-Based Relevance The quality of relevance within the hit list is one of the outstanding features of the iFinder5 elastic. It offers the possibility that the behavior of the user affects the relevance of the hit lists. Frequently selected search options and documents obtain more relevance, for example, even when considering the organigram. This way the user gets e.g. his colleague&apos;s filters suggested in his autocomplete function and so receives useful support for his research process. The iFinder5 elastic learns autonomously: the more something is searched, the bigger the influence on the relevance. Thereby the iFinder5 elastic offers the way from content-based relevance to usage-based relevance. Further Interesting Topics: This is how IntraFind supports departments or whole companies with intelligent search mechanisms and content analytics &gt;&gt;</body></Document><Document><url>https://www.intrafind.de/company/glossary/api</url><id>30E40E66FE732838AD8BF7983A308CA9</id><title>API</title><language>en</language><body>API   Application Programming Interface for programming interfaces in IT for exchanging information.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/gui</url><id>5769E5903E8699915465C0FA9472166E</id><title>GUI</title><language>en</language><body>GUI   Graphic User Interface / User Interface  </body></Document><Document><url>https://www.intrafind.de/company/glossary/structured-data</url><id>C5BC5FA437C332A74F40E9A0E4BE7B2B</id><title>Structured data</title><language>en</language><body>Structured data   Data that has a uniform structure (e.g. databases).  </body></Document><Document><url>https://www.intrafind.de/company/glossary/auto-classification</url><id>A1AD0AC903AF36728AA7DAA6AA8BE787</id><title>Auto-classification</title><language>en</language><body>Auto-classification   Auto-classification describes the systematic structure of classes based on characteristic values. The characteristics are obtained and assigned based on the classification. IntraFind uses TopicFinder for this.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/facet</url><id>65D57A545808573A2A4348C3A31661F3</id><title>Facet</title><language>en</language><body>Facet   Filter option in the standard view, but also in the knowledge map. Facets are based on metadata.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/index</url><id>085B5FFE6B0DE6415F7EBC6BC5B1D2BF</id><title>Index</title><language>en</language><body>Index   Corresponds to the analysis of databases. For the index structure, IntraFind initially determines the current real database, which reflects the file forms and sizes. Only after this the indexing process starts, which is the collection of information which then has the index as a result.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/linguistics</url><id>392DD300FBB526CF59AF9C4A4397EB96</id><title>Linguistics</title><language>en</language><body>Linguistics   The science that examines human languages. Linguistics is an important component in the area of intelligent search engines and text analysis. IntraFind has a market leading German linguistics program, LISA. The quality is particularly seen here as there are complex contextual connections. Other languages are available.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/information-access</url><id>DB2FFA2E8EAB5C2B0CDC62E541A56EB8</id><title>Information Access</title><language>en</language><body>Information Access   Users receive simple access to information through search engines.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/scalability</url><id>E686D29D09E1B62E524E14C2AE2D0E6F</id><title>Scalability</title><language>en</language><body>Scalability   In connection with software, scalability is seen as measures to increase the power of systems of hardware and software through the addition of further resources. One differentiates here between vertical (e.g. increasing memory) and horizontal (adding computers/nodes) scaling.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/auto-complete</url><id>B3E70195368437C37791241F31857BD2</id><title>Auto complete</title><language>en</language><body>Auto complete   If the user types a search term into the search field, the Enterprise Search solution iFinder suggests terms after a certain number of letters. This process eases the search and rules out the possibility of typos.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/tag</url><id>3DAA859DFD600978F865D760B0C06F00</id><title>Tag</title><language>en</language><body>Tag   A characteristic that describes content, image or text.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/knowledge-network</url><id>4B338E9E51B1C98E92E4B039C813CA6D</id><title>Knowledge network</title><language>en</language><body>Knowledge network   Knowledge networks or semantic networks serve the mapping of relations between objects. Compared to knowledge networks that are often constructed manually and provide access to information through a graphic interface, IntraFind offers the iFinder expansion module Semantic-associative Search, which is based on statistical calculations and allows for an associative search. It determines terms that are often found in the context of the entered search term and thus offers the searcher important support.  </body></Document><Document><url>https://www.intrafind.de/cms</url><id>5E19085EC5FB3D5DD36A6E7876994046</id><title>CMS</title><language>en</language><body>CMS   Content Management System  </body></Document><Document><url>https://www.intrafind.de/company/glossary/content-analytics</url><id>CC395069063FF655A03C414B41924332</id><title>Content analytics</title><language>en</language><body>Content analytics   The task of extracting corpus-wide insights, as e.g. correlations between concepts.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/crawler</url><id>2C940CA053A6E890A22AE9A90904F9CD</id><title>Crawler</title><language>en</language><body>Crawler   The Indexing Engine or the Crawler obtains data and documents from the data sources and lists these correspondingly in a structure, which in turn simplifies the search. Simultaneously, the Crawling Engine creates caches of the documents so that a document preview can be shown. The Query Engine runs through this index in order to list the hits.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/thesaurus</url><id>EBF19B73294AE9E0CC789C963C4D43B4</id><title>Thesaurus</title><language>en</language><body>Thesaurus   A thesaurus or word network contains synonyms, superordinate and subordinate terms.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/descriptor</url><id>DDA9786187D7B0829E7A22623B0B97F4</id><title>Descriptor</title><language>en</language><body>Descriptor   Keyword for the contextual description of an object, e.g. the topic of a text. The assignment of descriptors is a component of the contextual analysis of documents, e.g. in libraries. Normally, keywords are stored in a controlled vocabulary (e.g. standards file or thesaurus) and are assigned based on rules.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/boolean-search</url><id>554538D4171199B9777288DF855783BA</id><title>Boolean search</title><language>en</language><body>Boolean search   see Boolean operators  </body></Document><Document><url>https://www.intrafind.de/company/glossary/search-ergonomy</url><id>2E445A02C830DB3AD6FF6D85B79B8BC2</id><title>Search ergonomy</title><language>en</language><body>Search ergonomy   The arrangement of the user interface in different areas. Tests have shown that the arrangement of filters or facets is important for the positive valuation and usage of a search.  </body></Document><Document><url>https://www.intrafind.de/blog_en</url><id>DA8B9736DE76925D83CD81319FE10910</id><title>Enterprise Search Blog</title><language>en</language><body>ENTERPRISE SEARCH &amp; CONTENT ANALYTICS BLOG IntraFind experts provide there insights into the world of enterprise search, metadata extraction and usage as well as content analytics. Please feel free to share our blog with your colleagues or business partners.</body></Document><Document><url>https://www.intrafind.de/company/glossary/morphology</url><id>B7325C012828590C45F94927B42B284C</id><title>Morphology</title><language>en</language><body>Morphology   In linguistics, morphology is a part of grammar. Morphology deals with the internal structure of words and is dedicated to the study of the smallest meaningful and/or functional elements of a language, the morphemes. With regard to this, morphology - based on the term &quot;sentence grammar&quot; for syntax - is also known as &quot;word grammar&quot;. (11/28/2012 Wikipedia)  </body></Document><Document><url>https://www.intrafind.de/company/glossary/guided-search</url><id>349F7E293E14AC8401F772AC875306BE</id><title>Guided Search</title><language>en</language><body>Guided Search   Guided Search offers help in the search process through functions like the suggestion of search terms or the possibility to set filters. A characteristic of the IntraFind Guided Search is that the user can at any time see how he/she arrived at a certain result and thus can go back as well. Guided Search is particularly used in the Knowledge Map module.  </body></Document><Document><url>https://www.intrafind.de/blog_en/the-ifinder5-elastic-as-content-delivery-portal-cdp</url><id>E3BEB0F74BD325972A0E9098C7DB723A</id><title>The iFinder5 elastic as Content Delivery Portal (CDP)</title><language>en</language><body>The iFinder5 elastic as Content Delivery Portal (CDP) One product – many use cases... The launch of the new product generation iFinder5 elastic results in new use cases. One of them is &quot;Content Delivery&quot;, which aims at the aspect of the application-specific and user-friendly supply of quite static and - above all - quality assured information. Examples are multilingual manuals, wiring diagrams and handbooks - ultimately any kind of approved information, for example, for the operation and maintenance of a complex system or machine. These documents and contents are enriched with valuable information from the iFinder-based content delivery solution at the end of a content management process and are provided to the user. Imagine the whole as a two-step process: First, information, usually from different data sources, is aggregated and displayed with the help of search technologies. With Elasticsearch in the backend, the iFinder5 elastic uses the state-of-the-art NoSQL index technology and combines it with the latest semantic and linguistic text analysis methods. The iFinder5 elastic identifies all relevant content and the content manager selects and assembles the needed information package for the respective use case. This is then stored in the own data store of the iFinder. The second step is the tailored usage of the content - with IntraFind as online portal, also responsive on a smartphone or an iPad. The installed iFinder now displays all content application-specific and user-friendly. Application-specific means that wiring diagrams are displayed differently than complex multilingual manuals. User-friendly means that the iFinder supports the working process in various ways: The knowledge worker can navigate through contents and contexts. For a quick look-up, the best documents are displayed on the top of a well arranged hit list. By selecting categories like product or assembly group a technician can navigate through the knowledge map to the damaged component. Every user is able to research actively, is guided like in a modern online shop and is supported automatically throughout his research. Documents and metadata, which usually are maintained separately, are brought together when compiling the data and thereby information is put effortlessly into context. When compiling the information, it is possible to enrich unstructured content such as user manuals with metadata from structured data sources such as PLM databases. Another benefit of this solution is the possibility to automatically link contents which enables an easy navigation. An example will illustrate this: The searched assembly group is displayed as navigation object in the hit list. By clicking on the assembly group all other content will be filtered accordingly to this assembly group and the user sees all references - highlighted in color - in the entire stock of documents at a glance. An additional overview of all references within a single document facilitates a quick capturing of the contents. That is &quot;information in context at your fingertips&quot;, summarizes Franz Kögl, CEO, the benefits of the new IntraFind solution. The Author Manuel Brunner is an expert in search technologies. He has been working at IntraFind Software AG since 2008 and has managed the team Professional Services for many years. In his new role he took over the divisions Partner Management &amp; Business Development.</body></Document><Document><url>https://www.intrafind.de/blog_en/connectors-hidden-success-factor-for-universal-search</url><id>7D9DAAF871F9F434DFC244C6ECC5624F</id><title>Connectors - Hidden Success Factor for Universal Search</title><language>en</language><body>Connectors - Hidden Success Factor for Universal Search Single Source of Information. Is this the ultimate dream of all Enterprise Search Vendors, or is this reality about to happen? Call it Insight Engine, 360° View, or like earlier Enterprise Search and Universal Search, the common denominator is to provide search across as many enterprise information sources as humanly and technically possible, and then some. From 10,000 feet above, a great promise and the best solution for all current problems of information technology. Let’s find out. The successful vendors on the market utilize a search engine, very frequently Elasticsearch, and some do their own proprietary engine. Simplified, they do all the same. We at IntraFind long ago established for us that the search engine is commodity, earlier it was Lucene and today it is Elasticsearch. So why bother to create your own. And an Insight Engine is much more than a search engine. So, we put our efforts into integration and a soup to nuts, top to bottom product, that balances between the technologically possible and the user’s necessities. One area of importance is the sourcing of information, the enrichment of that information with meta data and the understanding of the security context of that information. All of that with the ultimate goal to provide the individual user with the insight to information across his and her relevant sources. Let’s call the sourcing of information from a specific source a connector. And the source can be anything from an Email System (like Microsoft Exchange and Lotus Domino) to an ERP product (from SAP to Microsoft Dynamics) to Line of Business Applications and any other content generating applications. For the vendor, we need to find the right slice of connectors to serve a wider user audience. If you do that on a project basis, no issues. Customer pays, and everyone lives happily ever after. That brings me to the point, that cost is not abstract at all. It can be the ultimate driver for a particular innovation, or its death sentence. If the benefit is not superior to the cost, why bother. If we, the software vendor, cannot provide value, no one will go for it. And especially with connectors, the cost of development grows with the measure, on how deep the connector is integrated into the source system. Let’s use ERP as an example. Under the fair assumption that an Insight Engine is not to replace the ERP product, but to extend the reach of the wealth of information of that ERP into the non-ERP user group, why deeply integrate and ask the Insight Engine to re-create the functionality of the ERP. Where in fact, most of the new users need only a portion of the information. A 360º view into the customer only needs to show whether an invoice has been paid or not, and maybe the dunning letters if they are of vital interest to the non-ERP user. If someone wants to know to what bank account an invoice has been paid, well, that is a question usually only of relevance to the FiCo team. And the FiCo team finds the answer in their ERP product, they will likely never look into the Insight Engine for that answer. Again, why bother to put that information there if nobody is using it. So, what is important? From my point of view, the information that there is an invoice, with its date and receiving party. If you need to look further, provide access to the original source from within the Insight Engine. And this is the first requirement, providing access. As simple as opening another application in a new window or more elaborate with embedding the original into the User Interface of the Insight Engine. Which one is best does not really matter, the user’s benefit is the judge. Let this be the first slice of our dreamed-of-connector. Having the data, and as such all the information now, it comes to the point of tailoring access to that information. Secured access to information, and not only from a legal data protection point of view, is pinnacle and must never be compromised or bargained with. It might sound as a contradiction, but usually a simplified authorization model for those documents just does very fine for Insight Engines. If detailed information (how much interest is in the invoice) is anyway not asked for using the Insight Engine, there is no need to ingest that information and data and consequently, there is no need to protect it. Assessing the audience very quickly helps simplify the efforts to secure the information against unauthorized access and view. The secure access is our next slice. We have the information and the data, we secured the access to the data, the next step is to provide a preview to the data. This preview helps our bespoken non ERP user to still use the wealth of information, without the need to learn how to use that software. The preview is our next slice in cutting down on our initial issue of not having a single source of information. Sourcing the information, guaranteeing security, providing a simple-to-use preview, these are all requirements a connector needs to support. And this being highly integrated into the Insight Engine, makes it become a powerful source of information. Users accessing distinct information through a single, easy to use, yet powerful Insight Engine, for me, that’s a problem solved. And if this really is the single source, that would be just the icing on the cake. I’ll have a slice of that. The combination of the search functionality and the slice of data and information does the trick. And the trick is: finding what needs to be found. The use cases differ even inside an organization, from e-discovery to a simple customer or project file. With the right combination of features and functions all those use cases can be solved with one product. And a little advertisement might be in order, we call this iFinder5 elastic. So, a well fitted Insight Engine is really the best thing since sliced bread. And this is ready and available to be used right here and right now. Slice yours today. Continue reading You would like to learn more about insight engines? Have a closer look at IntraFind&apos;s iFinder5 elastic. The Author Ralf Klinkhammer has almost 30 years of experience in the field of enterprise information management, having worked both nationally and internationally. Ralf is responsible for product management at Intrafind Software AG since 2014.  </body></Document><Document><url>https://www.intrafind.de/blog_en/difficult-relations-how-search-engines-can-be-expanded-by-means-of-word-families</url><id>B25B6CD73C3667A8BCE65870422BEF2A</id><title>Difficult Relations – How Search Engines Can Be Expanded by Means of Word Families</title><language>en</language><body>Difficult Relations – How Search Engines Can Be Expanded by Means of Word Families What makes a good search engine? The minimum requirement are those search functionalities, which are usually retrieved in a word processor or an editor by using the shortcut “CTRL   F”: You type a sequence of letters and the document is searched for all occurrences of this combination. This way you can quickly and easily find certain text passages within a document. Words, however, not always consist of the same letter sequences, but are dynamic entities: they are inflected depending on grammatical person, time, case or gender. For a user who wants to find out more about a particular topic or the use of a particular word, such a basic search functionality would certainly not be enough. Therefore, one way to extend the search is lemmatization: besides decomposition of compounds, lemmatization is a feature that builds the core of IntraFind’s linguistics and is based on the company&apos;s own full form lexicon. Thus, for example, the letter sequence &quot;thought&quot; is attributed to its basic form &quot;think&quot; in the lexicon as well as to all other possible forms of &quot;think&quot;. This way the entire spectrum of inflected word variants (inflectional paradigm) can be included in the search for one of these forms.   Words are dynamic entities - not only because they can be inflected, but also because they can be merged by so-called word-formation processes to form new words. With these neologisms they are in a kind of relation then. This relation may exist between words from the same part of speech, such as between the nouns &quot;chemistry&quot; and &quot;chemist&quot; or between words of different parts of speech such as &quot;chemistry&quot; and &quot;chemical&quot; or &quot;buy&quot; and &quot;buyer&quot;. A group of words that is in such a relation is called a word family. In many situations it can be useful for a search, to not only include the inflection paradigm, but also the word family. Because when someone is searching for &quot;chemistry&quot;, other search results that contain &quot;chemist&quot;, &quot;chemical&quot; and &quot;chemically&quot; might be interesting as well. For this, IntraFind developed a stem-thesaurus, in which the relation between members of a word family is stored. The thesaurus is a stem-thesaurus, because the criterion for the relation is a common word stem. This is a linguistically controversial term which can be defined as follows in this application: It is that part of the word the word family has in common and from which new words can be generated within the word family by adding pre- or suffixes. The word stem for our &quot;chemistry&quot;-family would be &quot;chem&quot; to which we can add the endings &quot;-ical&quot;, &quot;-istry&quot; and &quot;-ist&quot;.   The study of word formation processes shows that there are certain regularities in the derivation of words from the word stem: for example, nouns are mostly formed by adding the suffix &quot;-er&quot; or &quot;-ist&quot;. Rules of this kind can be implemented, so that a part of the thesaurus can be created automatically. However, it is also clear that there are too many exceptions in the language, so they can’t be corrected easily with only few additional exception rules. While the &quot;player&quot; is just someone who plays the &quot;liver&quot; is not a person who lives.   Particularly difficult is the relation with prefixes that strongly modify the meaning of the stem, even if they are still related: &quot;underwrite&quot; has something to do with &quot;write&quot;, but it&apos;s something different and shouldn’t be mixed up in a search query. Because of all these exceptions, it makes sense to store word families in a stem-thesaurus which is created with automatic support but also with half-automatic exception lists and a final manual check. The finished thesaurus contains only those word families, which feature a sufficient semantic relationship that makes them associated. It is then available as established but expandable resource to enlarge the range of search functionalities by the respective word family. Such semi-automatically generated and manually curated stem-thesauri are a valuable resource for exploratory search (see IntraFind&apos;s German blog post &quot;Tagging – Added Value by Metadata&quot;). By interacting with other features of the iFinder5 elastic they cater for a significant expansion of the search and research possibilities of the user. The Author Pascal Zambito, B.Sc., graduant of Computational Linguistics at the Ludwig-Maximilians-Universität München (LMU), has developed a stem- thesaurus for the German language as part of his thesis on behalf of Intrafind Software AG.</body></Document><Document><url>https://www.intrafind.de/blog_en/content-delivery-of-technical-information-429</url><id>FFB538D4E2CD2B0C0723A2C79F76FE83</id><title>Content Delivery of Technical Information</title><language>en</language><body>Content Delivery of Technical Information How can you use content intelligently? By classes and dynamic content delivery! Even nowadays technical documentation is mostly not valued as good or useful source of information. Too many incomprehensible or unmanageable documents have shaped the past and left behind frustrated or desperate users. Not to mention experts and technicians who prefer to rather trust their experience than long texts and inappropriate illustrations. Although a lot has changed dramatically in the past decades. In particular, special Content Management Systems (CMS) have been established for technical editing, whose basic principle is the modular information acquisition. The technical contents are registered in XML structures as &quot;modules&quot; or &quot;topics&quot; and assembled according to the technical configuration of the described product. Thus, documentations can be configured very efficiently as information products from reusable units. Variant-specific, market-dependent and – if necessary – customer-specific. Just like the products themselves. The targeted use and especially reuse of content in the specific CMS works when the modular content has intelligent, i.e. proper metadata for the intended use, that is suitable for different use cases. One frequently used method for this is the so-called PI-classification: Content modules carry unique information about the described hardware and software components of a product (&quot;p&quot;) and for each type of contained information (&quot;i&quot;). In this way, automatisms and selective (PI-) mechanisms can be used for efficient documentation. The reader benefits from accurate and targeted information. Actually. But often not. The reason is not the content but the media. Only slowly real electronic formats establish for the spread of documentations. Formats, more intelligent than monolithic PDFs; more intelligent to search and display. Also the known forms of online help and web formats often don’t meet the requirements – who hasn’t made this experience? Too little application-specific, too little searchable, or better, too little retrievable is the necessary information. So it was only logical that systems are recently formed that make the intelligence of data available to the user: New Content Delivery Portals (CDP) should tap the contents with the necessary navigation, search and access options: by navigating through traditional document structures (the indexes) and by dynamic filters and facets, e.g. via information classes, product components and variant features (inter alia according to the PI-classification). Finally, by direct search mechanisms in the content. In this way, many scenarios of information need and information use can be planned and fulfilled. Thereby, the application scenarios can be extremely different in reality. All process participants and all stations of the &quot;product lifecycle&quot; can benefit from more targeted information and especially from information available online: sales activities, production processes, training, installation and approval, service calls and so on. And also customers or rather users. From this follows that content delivery applications can or must have various forms and scales regarding the IT architecture: global Internet portals, internal company portals with limited access, product-oriented onsite portals as well as local computer-locked online help. And of course, all the mobile apps with offline, online and update mechanisms. So far, so helpful and good. Another dimension of the applications results, however, when one considers that a large amount of the content actually comes from sources that are not based on the modularity and are not deeply structured. A popular example is the vast number of service-related information, for example, from the areas of installation, diagnostics, error and application logs, or the mass of supplier information in mechanical and plant engineering. The more heterogeneous these sources, the more important they are for the application of a CDP and the more additional intelligent search and evaluation methods have to be used. In this case statistical, terminological, linguistic and/or ontological methods can serve to develop the content for the search and to make the information together with the structured information detectable. Thus, it is understandable that the providers are approaching the central topic content delivery in different ways: Content management systems of technical communication, service companies with portals as managed services, traditional company portals, tools for electronic (web) publications and also providers of search portals like IntraFind Software AG with their different technological possibilities of intelligently indexing structured and unstructured information. The market is heterogeneous and forms itself visibly for all companies that currently pursue and in the future will pursue a content delivery application scenario with the intelligent use of information. Drivers of the market are currently also &quot;Industry 4.0&quot; and the ubiquitous digitalization of products and services. To get an overview of the available solutions, the Content Delivery Symposium will again take place in Stuttgart, Germany this year. Continue reading You are interested in Content Delivery Portals (CDP)? Have a look at Manuel Brunner&apos;s blog post and learn more about how to use IntraFind&apos;s iFinder5 elastic as Content Delivery Portal. The Author Prof. Dr. Ziegler is Head of the Institute for Information and Content Management (I4ICM) of the Steinbeis Transfer Center at the University of Karlsruhe. In that capacity, he works on research transfer on current topics such as PI-Class, Content Intelligence (REx) and Content Delivery. At the University of Karlsruhe he teaches and does research in Communication and Media Management studies with a focus on the topics data, information, and content management.</body></Document><Document><url>https://www.intrafind.de/blog_en/new-high-quality-search-for-ifinder5-elastic</url><id>3C9439313882D86FADE630B16BE07DBF</id><title>New High Quality Search and Linguistics for iFinder5 elastic</title><language>en</language><body>New High Quality Search and Linguistics for iFinder5 elastic   IntraFind has long been known for high quality information retrieval. For our new product generation iFinder5 elastic we completely overhauled our core search technology consisting of our Lucene / Elasticsearch Analyzers and our Query Parser. The goal was to provide search that works intuitively from scratch without requiring any user training and that at the same time offers powerful new query operators for expert users. Furthermore, we wanted to minimize configuration efforts, especially in multilingual environments.   In part 1 of this blog article I talk about advantages for the standard user and how we are able to reduce configuration efforts. In part 2 I am going to talk about new features for experts such as our powerful new Near-Queries, Search Modes and future plans based on our concept of the Typed Index [1] [2].   Tokenization: Why it matters and why our users don’t have to care Search functionality provided by a search engine is different from text search people know e.g. from their text editors or office software. In your office software you can search for any substring of your text. The more text you have, the longer your search will take. The computational complexity for this kind of search is linear in the overall text size. Therefore, it is intractable for big document sets. Search engines like iFinder use a data structure called inverted file index (see Fig 1) to implement search efficiently for huge document sets. Fig 1: Inverted File Index The inverted file index consists of a term dictionary, which is an alphabetically sorted list of all words occurring within the document set, and posting lists for each word. A posting list is a list of all documents (their numbers), in which the word occurs together with the position of the word within the document. The good thing about the inverted file index is, that it allows to search for words from the term dictionary and combinations of them with high efficiency, even for huge document sets. The bad thing is, that it allows to search only for words that are in the term dictionary [1].   Every document / text is a stream of characters. The process that breaks it into words is called tokenization which is often followed by one or several normalization steps. The following example shows how tokenization influences and limits the kind of words for which we can search.   Text: “Send questions for OpenOffice to support@fufu.org”   Words generated by a standard tokenization &amp; lowercase normalization: send, questions, for, openoffice, to, support@fufu.org → No search results for “support” since it’s not a word in the term dictionary   Words generated by a splitting tokenizer and lowercase normalization: send, questions, for, open, office, to, support fufu org → No search results for “openoffice” (all lowercase) since there is no simple algorithmic way to know that it should be splitted [2]   Though a search engine can never provide efficient search for arbitrary substrings we come very close to that. We decided to use a tokenizer that allows very complex tokens such as email addresses, but we additionally split complex tokens into their parts and also add these parts as words to our term dictionary.   We not only split at special signs such as “@”, “-”, etc.., we also split CamelCase tokens such as OpenOffice and we split tokens when letters and numbers are adjacent. In this way users do not have to distinguish between “iphone6” and “iphone 6” when they search for information on their latest new iphone. Whatever reasonable assumption about words our users make, they find them with our search technology. [1] With Fuzzy-, Wildcard-, or Regex-Queries you can search for words that are not in the term dictionary. However, this kind of search is often very inefficient since it requires scanning big chunks of the term dictionary and the whole index. Furthermore, it requires some expert knowledge about the syntax of these query types. [2] &quot;OpenOffice&quot; could only be splitted based on a lexicon ressource that contains &quot;open&quot; and &quot;office&quot; as valid entries. Word Normalization: Why we need more than one normal form for a word In the last section about tokenization we also mentioned word normalization. We used a lowercase normalization in the example. Usually lowercase normalization is a good idea. However, sometimes case matters. There is a big company named “MAN” and we want to be able to distinguish a search for “MAN” from a search for “man”. Therefore, we also retain exact words besides normalized forms in our index.   In many languages we have diacritics or umlaut signs e.g. in “Amélie” or “Müller”. Very often, people do not type these special characters, especially when they type queries. Therefore, it is a reasonable normalization step to remove them. On the other hand, there might be a guy named “Muller” in our company and another guy named “Müller”. So we should still be able to distinguish both names in our search. Furthermore, there is more than one diacritics normal form. In Germany people tend to normalize “Müller” to “Mueller” while in other countries people will use “Muller”. We therefore have more than one diacritics normal form in our index.   A very import kind of word normalization concerns inflections. In many languages words occur in different forms in order to express grammatical roles such as tense, person, number, case, etc. If you search for “mouse” you also want to find “mice”.   Usually simple algorithmic stemmers are used to strip off typical suffixes of words in order to achieve this kind of normalization. However, these approaches tend to over- and understem.   Examples for stemming:    going → go decoder, decoding, decodes → decod Examples for overstemming:      Messer → mess      king → k Examples for understemming: spoke → speak     IntraFind has developed high quality morphological lexicons for most European languages which deliver much more accurate normalization than algorithmic stemmers. For a comparison of simple stemmers and morphological normalization see [3]. Some examples of lemmatization are shown in the following table.   English:       German: going → go (Verb)       lief → laufen (Verb) bought → buy (Verb)       rannte → rennen (Verb) bags → bag (Noun)       Bücher → Buch (Noun) bacteria → bacterium (Noun)       Taschen → Tasche (Noun)   Even this kind of high quality normalization is not always desirable. Our search engine also allows wildcard, fuzzy and regex searches. If the user searches for “mou*” (any term that starts with “mou”) he does not expect to find a document containing the word “mice”.  This means that besides morphologically normalized words we also need the original forms at least for wildcard, fuzzy or regex queries.   Phonetic normalization can also be very useful, especially for names. There are often different spelling variations for foreign names and a phonetic normal form allows to abstract from these more precisely than a simple fuzzy search.   Example for phonetic Normalization: Muhamed → MHMD    Mohammed → MHMD   We integrated phonetic normalizations such as Soundex, Metaphone, Double Metaphone, Cologne Phonetic and many more. They can easily be activated and since they are tuned for special languages we can activate them for each language individually. Since phonetic normalization makes most sense for proper names, we can optionally exclude normal words (identified by our morphological lexicons) from phonetic normalization making phonetic normal forms much more useful.   Each of these normal forms has its justification and is used for its own purposes. None of them is revolutionary new. Many of them are available as separate Lucene analyzers. We have integrated all these normal forms into one Lucene / Solr / Elasticsearch analyzer and all normal forms share one Lucene field. By using prefixes we are still able to distinguish different normal forms from each other. We call this approach the Typed Index (see e.g. [1], [2]). This approach has two key advantages.   First, it reduces configuration efforts considerably. We no longer need to specify different index fields and analyzers in complex mappings or index schemas and we don’t have to configure a complex query analysis. We only need one content field and one analyzer. Furthermore, we provide a query parser that allows to specify search modes for expert users, if they explicitly want to do exact search, search on lowercase / diacritics normal forms or on morphological normalized terms, and that implements a default search mode using all normal forms with configurable boosts for each of them. In this way, search for the non-expert user can be configured so that all possible matches are provided, but exact matches (MAN vs. man) are ranked much higher.   Second, since all normal forms are in one field, we can use word proximity information and can combine different normal forms in near or phrase queries. We can e.g. search for the words “book” and “Mohamed” close to each other with NEAR/2(book AND Mohamed) and this query will match a document containing “books of Muhammed”. For this match to work neither morphological normalization nor phonetic normalization alone would suffice, since “book” and “books” are phonetically different and for “Mohamed” to match “Muhammed” we need phonetic normalization. Note that this kind of Near Query that combines different normal forms is only possible with our Typed Index approach. Word decomposition and search When introducing tokenization, I already talked about additionally splitting complex words into their parts. Besides the plain algorithmic splitting methods described above, we have a very sophisticated linguistic compound decomposition based on lexicons and complex heuristics. Compound splitting is very important for German, which uses complex compound nouns where other languages tend to use phrases.   Some examples of German compounds: Kinderbuch   means   children’s book Bundesfamilienministerium   means   Federal Ministry for Family Issues   With our compound decomposition we can split these words into their lemmata (semantic parts) and we can even distinguish between head and modifier parts. The head word of “children’s book” is “book”, because it’s a special kind of book, modified by the modifier “child”. Whenever we search for “Buch” we also get matches for “Kinderbuch”.   Depending on the boosting-configuration we can boost compound matches equally high, higher or lower than matches for individual words and we can boost matches with head words higher than matches with modifiers. This means that “Buchladen” (book store) could score lower than “Kinderbuch” when we search for “Buch”. A search for “Bundesfamilienminsterium” will also match “Ministerium des Bundes für Familie”, a variant of expressing the same concept in a way more similar to other languages and equally frequent in German.   By the way, we recognize paragraph, sentence, and general separator boundaries in documents and usually forbid such boundaries within compound matches, complex token matches, and phrase / near searches. “Kinderbuch” will only match with occurrences of “Kind” and “Buch” if these two parts are close to each other and e.g. not in different sentences. Multiliguality and Mixed Language Documents Morphological normalization, word decomposition, and even phonetic normalization are usually language specific. The traditional approach to do search in a multilingual environment works by determining a language for each document and selecting a language-specific analyzer based on the result. User Queries are usually expanded into all configured languages.   This approach has two disadvantages. It requires complex configuration (mappings, index schemata) and it cannot handle mixed language documents (emails in which users switch between languages, documents with an English abstract and French content, etc.). In my last blog article I talked about language identification and language chunking [4]. Our language chunker splits arbitrary text into chunks of the same language. See Fig 2 for an example.   Fig 2: Language Chunking: Different Chunks are marked with different colours.   We have integrated the language chunker into our analyzer. Document content is first splitted into chunks of the same language and for each chunk a language-specific analysis is started. All terms / words end up in the same field, language-specific normal forms are again distinguished by their prefix (typed index). This way, no additional configuration is needed and we can handle mixed-language documents in a natural way. [1] “The Typed Index”, C. Goller, FOSDEM 2015, https://archive.fosdem.org/2015/schedule/event/the_typed_index/ [2] “The Typed Index”, C. Goller, Lucene Revolution 2013, Dublin, https://www.youtube.com/watch?v=X93DaRfi790 [3] “The difference between stemming and lemmatization”, U. Seisenberger, IntraFind Blog, https://www.intrafind.de/en/blog/blog-details/the-difference-between-stemming-and-lemmatization-380 [4] Language Identification and Language Chunking, C. Goller, IntraFind Blog, https://www.intrafind.de/en/blog/blog-details/language-identification-and-language-chunking-381 The Author Christoph has more than 15 years of experience in the search industry. He got a Ph.D in computer science from the Technical University of Munich where he worked in several research projects on artificial intelligence, machine learning and neural networks.   From 2003 to 2007 he was one of the main committers in the Apache open source project Lucene. As research director of IntraFind (since 2002) Christoph is responsible for IntraFind&apos;s core search and content analytics technology.    </body></Document><Document><url>https://www.intrafind.de/blog_en/language-identification-and-language-chunking-381</url><id>C2D67B0E882110CBA926A1DC4DBB751E</id><title>Language Identification and Language Chunking</title><language>en</language><body>Language Identification and Language Chunking   Identifying the language of a given text is a crucial preprocessing step for almost all text analysis methods. It is considered as a solved problem since more than 20 years. Available solutions build on the simple observation that for all languages typical letter sequences (letter n-grams) exist, that occur significantly more frequent in this language than in other languages. Even the frequency of individual letters differs significantly for European languages. The letter “e” is the most frequent single letter in most European languages, but for Polish the most frequent letter is “a”.   Figure 1: All letter n-grams of length 1 (unigram) to 4 (tetra gram) for &quot;TEXT&quot; with &quot;_&quot; as marker for start and end of text Tika: Cavnar &amp; Trenkle Approach All existing solutions for language identification build some kind of letter n-gram model or profile for every language, which is then compared with the letter n-gram profile of the text that is analyzed. A very simple approach was described in [C&amp;T94] and is still used by the Apache Tika language identifier. The profiles generated in their approach simply consist of the most frequent letter n-grams sorted according to their frequency and the comparison of text and language profiles is based on a heuristic measure which compares the rank of letter n-grams in both profiles:   Figure 2: Apache Tika / C&amp;T94 Approach   As stated already in the beginning, language identification is considered a solved problem. For text that is longer than 100 characters, there are methods that identify the correct language with an accuracy of 99%. This means that we might still have ten thousand incorrectly classified documents in a 1 million documents collection. So there is definitely still room for improvement. Furthermore, accuracy of established approaches drops considerably if we consider shorter text chunks like tweets or search engine queries.   Since there is an increasing need for accurate language identification for short text, research activity in the field has increased during the last 5 years. At IntraFind we recently also decided to take a closer look at language identification. I think we got some interesting findings.   First we tested the simple Apache Tika implementation on the LIGA benchmark (language identifier benchmark on twitter data, see [T&amp;P11]). We got an accuracy of 97.7%, much better than the 93% reported by [T&amp;P11] with the Tika implementation. In contrast to [T&amp;P11] we used our own training data set which is much bigger than the data set used by [T&amp;P11] (they used cross validation on the benchmark itself). Our result is even slightly better than the result achieved by [T&amp;P11] with their own very sophisticated new approach. This shows that using big sets of training data is important.   Google: Naïve Bayes Established approaches for language identification such as the Naïve Bayes approaches used by the current Google implementations (e.g. the Chromium Language Detector used in the Chrome Browser) use a fixed n-gram length. Usually an n-gram length of 4 is used for European languages and a length of 2 is used for Chinese or Japanese. For a comparison see [McC11].   Latest Developments Latest developments that try to improve language identification accuracy consider longer n-grams. This is motivated by the fact, that languages are not only characterized by typical short letter n-grams. Humans recognize languages because they know frequent words and those words are usually longer than 4 letters.   We tested a language identifier based simply on counting the number of matching words for each language using our morphological lexica and achieved an accuracy of 99.4% on the LIGA benchmark. This is better than the best result reported on that benchmark (as far as we know) and it confirms the idea that a fixed short n-gram length is incompatible with further improvements in language identification. However, language identification is considered as a preprocessing step which should be very fast. Lexicon lookup is not a practical solution, especially since good morphological lexica might not be available for all languages.   Markov Chain Standard Naïve Bayes n-gram approaches do not allow to consider variable-length n-grams in a straightforward way. We therefore decided to use a Markov Chain model [Dun94], which actually allows to use variable-length n-grams by using a back-off approach for estimating letter n-gram probabilities. With our current implementation we achieve an accuracy of 99.2% on the LIGA benchmark, which is identical to the best published result that we know.   Furthermore our Java-based implementation is very fast. On a current notebook processor with one thread we achieve a throughput of 5.5 MB/sec (counting each character as one byte), which is approximately 5 times faster than the Apache Tika implementation and comparable to the performance of the fastest existing language identifier (Google’s Chromium language detector).   Language identification is not the only goal we wanted to achieve with our new language identifier. It can be used to automatically identify chunks with the same language within a given text and since we have a high accuracy for short text we are even able to identify short chunks (see figure 3).   German Tweet: “Ich mag den Song la vie en rose sehr gerne.” Chunk 1: Ich mag den Song language: de Chunk 2: la vie en rose language: fr Chunk 3: sehr gerne language: de Fig 3: Language Chunking Example     Bibliography:   &quot;Gram-Based Text Categorization&quot;, William B. Cavnar , John M. Trenkle, In Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval, 1994 [T&amp;P11] “Graph-based n-gram language identification on short texts.”, Erik Tromp and Mykola Pechenizkiy, In Proceedings of Benelearn, The Hague, Netherlands, 2011 [Dun94] “Statistical Identification of Language”, Ted Dunning, Technical Report New Mexico State University, 1994 [McC11] “Accuracy and performance of Google&apos;s Compact Language Detector”, Michael McCandless Blog: https://blog.mikemccandless.com/2011/10/accuracy-and-performance-of-googles.html The Author Christoph has more than 15 years of experience in the search industry. He got a Ph.D in computer science from the Technical University of Munich where he worked in several research projects on artificial intelligence, machine learning and neural networks.   From 2003 to 2007 he was one of the main committers in the Apache open source project Lucene. As research director of IntraFind (since 2002) Christoph is responsible for IntraFind&apos;s core search and content analytics technology.    </body></Document><Document><url>https://www.intrafind.de/company/glossary/entity-recognition</url><id>78E0D76B1A52DE48058C54CBE7F4F5D7</id><title>Entity recognition</title><language>en</language><body>Entity recognition   Recognition of descriptions, meanings, word origins or translations  </body></Document><Document><url>https://www.intrafind.de/company/glossary/metadata-generation</url><id>68A4032219C0DBB7991D71D4158926D2</id><title>Metadata generation</title><language>en</language><body>Metadata generation   Existence of characteristics that describe data. Can also be understood as properties of a document, book, etc. Typical metadata for a book includes, for example, the name of the author, the edition, the year of publication, the publishing house and the ISBN. This metadata is often collected manually in companies and entered into the properties of a document. The objective is to simplify, standardize and ultimately automate the metadata generation process through intelligent methods or products.  </body></Document><Document><url>https://www.intrafind.de/company/corpus</url><id>B46CCE894E33B873BC7FAA5FBB549BF3</id><title>Corpus</title><language>en</language><body>Corpus   In linguistics, a corpus is a set of (representative) texts or utterances in a particular language. This can for example be used for the training of the text classification product TopicFinder.  </body></Document><Document><url>https://www.intrafind.de/company/glossary/connector</url><id>07073865FBC0C16FF22E62D073AE675D</id><title>Connector</title><language>en</language><body>Connector   Connectors provide the connection between the search engine iFinder and the respective end systems such as databases, Microsoft Exchange, Lotus Notes or also the file system. For this they use converters in order to extract the content, for example, from Office documents. Furthermore, the connectors read metadata from the end system in order to enrich the search index.   Connectors regularly update the index. The update can be executed automatically by the operating system in a scheduled task or it can be initiated by the end system itself (near-time indexing).  </body></Document><Document><url>https://www.intrafind.de/company/glossary/log-file</url><id>BA724569B876F16D9ABC71C5EDF976CF</id><title>Log file</title><language>en</language><body>Log file   A log file contains an automatic log of all or certain actions of processes in a computer system. www.wikipedia.de  </body></Document><Document><url>https://www.intrafind.de/news_en</url><id>1C7264AF8FDE0D3C14BCC6EBA2CA5C36</id><title>News of IntraFind Software AG</title><language>en</language><body>IntraFind News</body></Document><Document><url>https://www.intrafind.de/company/glossary/e-commerce</url><id>2BFF0187B668958F0D0E398A99AC2B9B</id><title>E-Commerce</title><language>en</language><body>E-Commerce   Business processes such as the sale of goods or services are increasingly automated through electronic trading platforms (e.g. online shops or portals) conducted on the Internet. A powerful search, that is the opportunity for visitors to quickly and easily find their favorite items and content on the site, may have a significant impact on the length of their stay or on the generated volume of sales.     IntraFind offers comprehensive support for the qualitative optimization of shop search. This includes improved language features through the use of text analysis and guided search as well as analysis capabilities by using the knowledge map, or assistance with data collection and refinement. Get to know more about the industry solution E-commerce.  </body></Document></documents>